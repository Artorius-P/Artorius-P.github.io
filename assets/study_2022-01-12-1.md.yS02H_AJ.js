import{_ as a,c as s,o as e,ag as i}from"./chunks/framework.tfLYlFWj.js";const k=JSON.parse('{"title":"爬虫学习笔记","description":"","frontmatter":{"title":"爬虫学习笔记","date":"2022-01-12T00:00:00.000Z","lang":"zh_CN","categories":["study"]},"headers":[],"relativePath":"study/2022-01-12-1.md","filePath":"study/2022-01-12-1.md","lastUpdated":1758246806000}'),l={name:"study/2022-01-12-1.md"};function n(d,t,p,h,r,o){return e(),s("div",null,[...t[0]||(t[0]=[i(`<h1 id="爬虫学习笔记" tabindex="-1">爬虫学习笔记 <a class="header-anchor" href="#爬虫学习笔记" aria-label="Permalink to &quot;爬虫学习笔记&quot;">​</a></h1><h2 id="xpath" tabindex="-1">XPath <a class="header-anchor" href="#xpath" aria-label="Permalink to &quot;XPath&quot;">​</a></h2><h3 id="xpath路径表达式" tabindex="-1">XPath路径表达式 <a class="header-anchor" href="#xpath路径表达式" aria-label="Permalink to &quot;XPath路径表达式&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:left;">表达式</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">nodename</td><td style="text-align:left;">选取此节点的所有子节点</td></tr><tr><td style="text-align:left;">/</td><td style="text-align:left;">从根节点选取</td></tr><tr><td style="text-align:left;">//</td><td style="text-align:left;">从匹配选择的当前节点选择文档中的节点，不考虑它们的位置</td></tr><tr><td style="text-align:left;">.</td><td style="text-align:left;">选取当前的节点</td></tr><tr><td style="text-align:left;">..</td><td style="text-align:left;">选取当前的父节点</td></tr><tr><td style="text-align:left;">@</td><td style="text-align:left;">选取属性</td></tr><tr><td style="text-align:left;">例如，选出相对路径下所有class1属性的a标签内的文字</td><td style="text-align:left;"></td></tr></tbody></table><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>.//a[@class=&quot;class1&quot;]/text()</span></span></code></pre></div><h3 id="通配符" tabindex="-1">“*”通配符 <a class="header-anchor" href="#通配符" aria-label="Permalink to &quot;“*”通配符&quot;">​</a></h3><table tabindex="0"><thead><tr><th style="text-align:left;">表达式</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">/school/*</td><td style="text-align:left;">选取school元素的所有子元素</td></tr><tr><td style="text-align:left;">//*</td><td style="text-align:left;">选取文档中的所有元素</td></tr><tr><td style="text-align:left;">//name[@*]</td><td style="text-align:left;">选取所有带有属性的元素</td></tr></tbody></table><h3 id="运算符" tabindex="-1">“|”运算符 <a class="header-anchor" href="#运算符" aria-label="Permalink to &quot;“|”运算符&quot;">​</a></h3><p>如果匹配多个路径，则可以使用<code>|</code>运算符。比较简单，不举例了。</p><h3 id="xpath-其他运算符" tabindex="-1">XPath 其他运算符 <a class="header-anchor" href="#xpath-其他运算符" aria-label="Permalink to &quot;XPath 其他运算符&quot;">​</a></h3><p>加减乘，大于小于不等于这些闭着眼睛都能写。几个特例除外</p><ul><li><code>div</code> 除法</li><li><code>or</code> 或</li><li><code>and</code> 与</li><li><code>mod</code> 模</li></ul><h2 id="scrapy的编写流程" tabindex="-1">Scrapy的编写流程 <a class="header-anchor" href="#scrapy的编写流程" aria-label="Permalink to &quot;Scrapy的编写流程&quot;">​</a></h2><p>首先用scrapy自带的脚本创建project</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>scrapy startproject myproject</span></span></code></pre></div><p>接着进入该目录，创建第一个爬虫程序，注意不可以跟项目同名</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>scrapy genspider myspider mysite.com</span></span></code></pre></div><p>创建完成之后会有在sipder文件夹里生成一个Spider类，对应网页的spider就可以在这里编写。 另外，在上级文件夹里还有几个文件。</p><p>在settings.py里可以设置爬虫的参数，例如headers,user-agent,并发数量，等待时间等等。</p><p>在items类里可以定义爬取的item，例子如下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scrapy</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> EthItem</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scrapy</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Item</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # define the fields for your item here like:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # name = scrapy.Field()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    contract </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scrapy.Field()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scrapy.Field()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    date </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scrapy.Field()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    txs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scrapy.Field()</span></span></code></pre></div><p>在spider类里爬取到的item需要通过yield item的形式传入管道，每个管道对收到的item进行特定的操作并传出，管道执行的优先级可以在settings.py里进行设置。</p>`,22)])])}const y=a(l,[["render",n]]);export{k as __pageData,y as default};
